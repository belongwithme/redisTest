@[TOC](缓存更新策略)
## 什么是缓存更新策略
缓存更新策略是指当数据发生变化时，如何保持缓存和数据库中数据一致的方法。想象一下，你有一本字典（数据库）和一张笔记（缓存），当字典内容变化时，你需要决定如何更新笔记。

## 基本的缓存更新策略
### 旁路缓存(Cache Aside)
这是最常见的策略，就像你查单词一样：
读取流程：
- 先看笔记（缓存）有没有这个单词
- 如果笔记上有，直接使用
- 如果笔记上没有，去查字典（数据库）
- 查到后，把单词写在笔记上，下次就能直接看笔记了
更新流程：
- 直接修改字典（数据库）中的单词解释
- 把笔记（缓存）上对应的单词划掉（删除缓存）
- 下次需要时，会重新查字典并更新笔记

代码:
```java
// 读取商品信息
public Product getProduct(Long id) {
    // 步骤1：查询缓存
    String key = "product:" + id;
    Product product = redis.get(key);
    
    // 步骤2：缓存未命中，查询数据库
    if (product == null) {
        product = database.findProduct(id);
        
        // 步骤3：将查询结果放入缓存
        if (product != null) {
            redis.set(key, product, 1小时);
        }
    }
    
    return product;
}

// 更新商品信息
public void updateProduct(Product product) {
    // 步骤1：更新数据库
    database.updateProduct(product);
    
    // 步骤2：删除缓存
    String key = "product:" + product.getId();
    redis.delete(key);
}
```
优点：
- 简单易懂，容易实现
- 适合读多写少的场景（比如商品信息）
缺点：
如果多人同时操作，可能出现数据不一致
例如：小明删除缓存后，小红读取旧数据并写入缓存，导致缓存中是旧数据


###  Read/Write Through（读写穿透）
这种策略就像你请了一个助手帮你管理笔记和字典：
读取流程：
- 你只需要问助手要单词解释
- 助手先看笔记
- 如果笔记没有，助手去查字典，然后更新笔记
- 助手把答案告诉你
更新流程：
- 你告诉助手要修改单词解释
- 助手同时更新字典和笔记

```java
// 使用Spring Cache简化实现
@Service
public class ProductService {
    
    @Cacheable(value = "products", key = "#id")
    public Product getProduct(Long id) {
        // 缓存未命中时自动调用此方法并缓存结果
        return database.findProduct(id);
    }
    
    @CachePut(value = "products", key = "#product.id")
    public Product updateProduct(Product product) {
        // 更新数据库并自动更新缓存
        database.updateProduct(product);
        return product;
    }
}
```
优点：
- 你不需要关心缓存逻辑，框架帮你处理
- 缓存和数据库总是一起更新，一致性更好
缺点：
- 更新操作变慢了，因为要同时更新两个地方
- 如果助手（缓存框架）出问题，可能两边都更新失败


### Write Behind（异步写回）
这种策略像是助手先记在笔记上，然后定期更新字典：
读取流程：
- 与Read Through相同
更新流程：
- 你告诉助手修改单词解释
- 助手立即更新笔记
- 助手在空闲时（比如每隔10分钟）批量更新字典
```java
// 更新商品（简化版）
public void updateProduct(Product product) {
    // 步骤1：更新缓存
    String key = "product:" + product.getId();
    redis.set(key, product);
    
    // 步骤2：将更新任务加入队列，稍后批量更新数据库
    updateQueue.add(product);
}

// 后台线程定期执行
public void processBatchUpdates() {
    List<Product> batch = new ArrayList<>();
    
    // 收集队列中的更新任务
    updateQueue.drainTo(batch, 100);
    
    if (!batch.isEmpty()) {
        // 批量更新数据库
        database.batchUpdate(batch);
    }
}
```
优点：
- 更新操作非常快，因为只更新了缓存
- 可以合并多次更新，减轻数据库负担
- 适合频繁更新的数据（如游戏积分）
缺点：
- 如果系统崩溃，队列中的更新可能丢失
- 数据库和缓存可能长时间不一致
- 不适合对一致性要求高的场景（如银行余额）

### 延迟双删策略
这是对Cache Aside的改进，解决了并发问题：
更新流程：
- 先删除笔记上的单词（删除缓存）
- 更新字典中的单词（更新数据库）
- 等一小会儿（比如0.5秒）
- 再次删除笔记上的单词（再次删除缓存）
代码示例：
```java
public void updateProduct(Product product) {
    String key = "product:" + product.getId();
    
    // 步骤1：先删除缓存
    redis.delete(key);
    
    // 步骤2：更新数据库
    database.updateProduct(product);
    
    // 步骤3：等待一段时间后再次删除缓存
    new Thread(() -> {
        try {
            // 等待500毫秒
            Thread.sleep(500);
            // 再次删除缓存
            redis.delete(key);
        } catch (Exception e) {
            // 处理异常
        }
    }).start();
}
```
为什么要等待后再删一次？
想象这个场景：
1. 小明开始更新商品，先删除了缓存
2. 小红这时来查询商品，发现缓存没有，就去查数据库（还是旧数据）
3. 小红把旧数据放入缓存
4. 小明更新数据库完成
5. 结果缓存里还是旧数据！
有了第二次删除，就能解决这个问题，因为会把小红放入的旧数据删掉。
优点：
解决了并发情况下的缓存不一致问题
实现相对简单
缺点：
- 需要额外的线程来执行延迟删除
- 延迟时间不好确定，太短可能无效，太长可能影响性能


## 如何选择适合的策略
可以遵循这些简单原则：
- 一般情况：使用Cache Aside（更新数据库，删除缓存）
- 高并发场景：考虑使用延迟双删策略
- 框架支持：如果使用Spring Cache等框架，可以采用Read/Write Through
- 特殊场景：对于统计数据等可以容忍不一致的场景，可以考虑Write Behind

## 实例-电商商品系统的缓存更新策略
通过一个电商商品系统的例子，详细解释不同场景下如何选择和实现缓存更新策略。电商系统是一个很好的例子，因为它包含了不同特性的数据和业务场景。
商品系统的主要数据类型
电商商品系统通常包含以下几类数据：
1. 商品基本信息：名称、描述、图片等，读多写少
2. 商品库存：实时库存数量，读写频繁且一致性要求高
3. 商品价格：可能会有促销、秒杀等活动导致频繁变化
4. 商品评论和评分：用户生成内容，写入频繁但一致性要求较低
5. 商品分类和标签：相对稳定，读多写少

### 场景一：商品基本信息（Cache Aside策略）
业务特点
- 读取频率高：用户浏览商品详情
- 更新频率低：运营人员偶尔更新商品信息
- 一致性要求：中等（用户可以接受短暂的信息不一致）
实现方案:
```java
@Service
public class ProductInfoService {
    
    @Autowired
    private ProductRepository productRepository;
    
    @Autowired
    private StringRedisTemplate redisTemplate;
    
    private final ObjectMapper objectMapper = new ObjectMapper();
    
    // 获取商品基本信息
    public ProductInfo getProductInfo(Long productId) {
        String cacheKey = "product:info:" + productId;
        
        // 1. 先查询缓存
        String cachedProductJson = redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedProductJson != null) {
            try {
                // 缓存命中，直接返回
                return objectMapper.readValue(cachedProductJson, ProductInfo.class);
            } catch (Exception e) {
                // 缓存数据异常，删除缓存
                redisTemplate.delete(cacheKey);
            }
        }
        
        // 2. 缓存未命中，查询数据库
        ProductInfo productInfo = productRepository.findProductInfoById(productId);
        
        if (productInfo != null) {
            try {
                // 3. 将查询结果放入缓存，设置过期时间为1天
                String productJson = objectMapper.writeValueAsString(productInfo);
                redisTemplate.opsForValue().set(cacheKey, productJson, 24, TimeUnit.HOURS);
            } catch (Exception e) {
                log.error("Failed to cache product info: " + productId, e);
            }
        }
        
        return productInfo;
    }
    
    // 更新商品基本信息
    @Transactional
    public void updateProductInfo(ProductInfo productInfo) {
        // 1. 更新数据库
        productRepository.save(productInfo);
        
        // 2. 删除缓存
        String cacheKey = "product:info:" + productInfo.getId();
        redisTemplate.delete(cacheKey);
        
        log.info("Product info updated and cache deleted: " + productInfo.getId());
    }
}
```
#### 详细解释
1. 读取流程：
- 首先检查Redis缓存中是否有商品信息
- 如果有，直接返回缓存数据（提高响应速度）
- 如果没有，从数据库查询，然后存入缓存（为下次访问做准备）
- 设置1天的过期时间，防止缓存长期不更新
2. 更新流程：
- 先更新数据库，确保数据持久化
- 然后删除缓存，而不是更新缓存
- 下次有人查询时，会从数据库重新加载最新数据到缓存
为什么选择Cache Aside：
- 实现简单，容易理解和维护
- 商品基本信息读多写少，非常适合这种策略
- 即使出现短暂的数据不一致，对用户体验影响也不大

### 场景二：商品库存（延迟双删策略）
业务特点
- 读取频率高：用户浏览商品、加入购物车时需要检查库存
- 更新频率高：每次下单都会减少库存
- 一致性要求：高（显示错误的库存可能导致用户下单失败）
实现方案:
```java
@Service
public class ProductInventoryService {
    
    @Autowired
    private InventoryRepository inventoryRepository;
    
    @Autowired
    private StringRedisTemplate redisTemplate;
    
    @Autowired
    private ThreadPoolTaskScheduler taskScheduler;
    
    // 获取商品库存
    public int getProductStock(Long productId) {
        String cacheKey = "product:stock:" + productId;
        
        // 1. 先查询缓存
        String cachedStock = redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedStock != null) {
            try {
                return Integer.parseInt(cachedStock);
            } catch (NumberFormatException e) {
                // 缓存数据异常，删除缓存
                redisTemplate.delete(cacheKey);
            }
        }
        
        // 2. 缓存未命中，查询数据库
        Inventory inventory = inventoryRepository.findByProductId(productId)
            .orElseThrow(() -> new ProductNotFoundException("Product not found: " + productId));
        
        int stock = inventory.getAvailableStock();
        
        // 3. 将查询结果放入缓存，设置较短的过期时间（5分钟）
        redisTemplate.opsForValue().set(cacheKey, String.valueOf(stock), 5, TimeUnit.MINUTES);
        
        return stock;
    }
    
    // 减少商品库存（下单时调用）
    @Transactional
    public boolean deductStock(Long productId, int quantity) {
        String cacheKey = "product:stock:" + productId;
        
        // 1. 先删除缓存
        redisTemplate.delete(cacheKey);
        log.info("Cache deleted before stock update: " + productId);
        
        try {
            // 2. 更新数据库
            int updatedRows = inventoryRepository.deductStock(productId, quantity);
            
            if (updatedRows == 0) {
                // 库存不足或商品不存在
                log.warn("Failed to deduct stock for product: " + productId);
                return false;
            }
            
            // 3. 延迟双删：再次删除缓存
            taskScheduler.schedule(() -> {
                try {
                    redisTemplate.delete(cacheKey);
                    log.info("Cache deleted again after stock update: " + productId);
                } catch (Exception e) {
                    log.error("Error in delayed cache deletion: " + productId, e);
                }
            }, new Date(System.currentTimeMillis() + 500)); // 延迟500毫秒
            
            return true;
        } catch (Exception e) {
            log.error("Error updating stock: " + productId, e);
            throw e;
        }
    }
    
    // 库存仓库接口
    public interface InventoryRepository extends JpaRepository<Inventory, Long> {
        @Modifying
        @Query("UPDATE Inventory i SET i.availableStock = i.availableStock - :quantity " +
               "WHERE i.productId = :productId AND i.availableStock >= :quantity")
        int deductStock(@Param("productId") Long productId, @Param("quantity") int quantity);
        
        Optional<Inventory> findByProductId(Long productId);
    }
}
```
#### 详细解释
1. 读取流程：
- 与商品基本信息类似，先查缓存，缓存未命中则查数据库
- 但缓存过期时间设置较短（5分钟），因为库存变化频繁
- 使用简单的数字存储，而非完整对象，减少序列化开销
2. 更新流程（延迟双删）：
- 先删除缓存，防止其他线程读取到旧数据
- 更新数据库中的库存
- 延迟500毫秒后再次删除缓存
这样即使在更新过程中有线程读取旧数据并写入缓存，第二次删除也能清除它
为什么选择延迟双删：
- 库存是高频更新且一致性要求高的数据
- 在高并发场景下，普通的Cache Aside可能导致缓存数据不一致
延迟双删能有效减少不一致窗口，提高库存数据的准确性
额外的库存保护：
- 使用数据库条件更新（availableStock >= :quantity）确保不会出现负库存
- 返回更新行数来判断操作是否成功

### 场景三：商品评论数（Write Behind策略）
业务特点
- 读取频率高：用户浏览商品详情时显示评论数
- 更新频率高：用户不断提交新评论
- 一致性要求：低（评论数短时间内不精确影响不大）
实现方案:
```java
@Service
public class ProductReviewService {
    
    @Autowired
    private ReviewRepository reviewRepository;
    
    @Autowired
    private StringRedisTemplate redisTemplate;
    
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);
    
    @PostConstruct
    public void init() {
        // 每5分钟将缓存中的评论数同步到数据库
        scheduler.scheduleAtFixedRate(this::syncReviewCountsToDatabase, 
                                     5, 5, TimeUnit.MINUTES);
    }
    
    // 获取商品评论数
    public long getReviewCount(Long productId) {
        String cacheKey = "product:review_count:" + productId;
        
        // 1. 查询缓存
        String cachedCount = redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedCount != null) {
            try {
                return Long.parseLong(cachedCount);
            } catch (NumberFormatException e) {
                // 缓存数据异常，删除缓存
                redisTemplate.delete(cacheKey);
            }
        }
        
        // 2. 缓存未命中，查询数据库
        long count = reviewRepository.countByProductId(productId);
        
        // 3. 将查询结果放入缓存
        redisTemplate.opsForValue().set(cacheKey, String.valueOf(count), 1, TimeUnit.HOURS);
        
        return count;
    }
    
    // 添加新评论
    @Transactional
    public void addReview(Review review) {
        // 1. 保存评论到数据库
        reviewRepository.save(review);
        
        // 2. 更新缓存中的评论计数（增加1）
        String cacheKey = "product:review_count:" + review.getProductId();
        redisTemplate.opsForValue().increment(cacheKey, 1);
        
        // 3. 记录待更新的商品ID
        redisTemplate.opsForSet().add("products:review_count_changed", 
                                     String.valueOf(review.getProductId()));
    }
    
    // 定期将缓存中的评论数同步到数据库
    private void syncReviewCountsToDatabase() {
        try {
            // 获取所有需要更新的商品ID
            Set<String> productIds = redisTemplate.opsForSet()
                .members("products:review_count_changed");
            
            if (productIds == null || productIds.isEmpty()) {
                return;
            }
            
            for (String productIdStr : productIds) {
                try {
                    Long productId = Long.parseLong(productIdStr);
                    String cacheKey = "product:review_count:" + productId;
                    
                    // 获取缓存中的评论数
                    String cachedCount = redisTemplate.opsForValue().get(cacheKey);
                    
                    if (cachedCount != null) {
                        long count = Long.parseLong(cachedCount);
                        
                        // 更新数据库中的评论计数
                        reviewRepository.updateReviewCount(productId, count);
                        log.info("Synced review count to database: " + productId + " = " + count);
                    }
                    
                    // 从待更新集合中移除此商品ID
                    redisTemplate.opsForSet().remove("products:review_count_changed", productIdStr);
                    
                } catch (Exception e) {
                    log.error("Error syncing review count for product: " + productIdStr, e);
                }
            }
        } catch (Exception e) {
            log.error("Error in review count sync job", e);
        }
    }
}
```
#### 详细解释
1. 读取流程：
- 与前面的例子类似，先查缓存，缓存未命中则查数据库
- 评论数是一个简单的数字，直接存储字符串形式
2. 更新流程（Write Behind）：
- 新评论保存到数据库（保证数据不丢失）
- 立即更新缓存中的评论计数（使用Redis的increment操作）
- 将商品ID添加到"待更新"集合中
后台任务每5分钟运行一次，将缓存中的评论数同步到数据库
为什么选择Write Behind：
- 评论数更新非常频繁，但精确性要求不高
- 批量更新数据库减少了数据库负担
- 用户能立即看到自己的评论计数变化（提升体验）
- 即使出现短暂不一致，也不会影响核心业务
实现细节：
- 使用Redis的Set存储待更新的商品ID，避免重复
- 使用Redis的increment操作原子性地增加计数
- 定时任务确保数据最终一致性

### 场景四：商品分类（Read/Write Through策略）
业务特点
- 读取频率高：用户浏览分类、筛选商品
- 更新频率低：运营人员偶尔调整分类
- 一致性要求：中等（分类信息相对稳定）
实现方案:
```java
@Configuration
@EnableCaching
public class CacheConfig {
    
    @Bean
    public CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(24))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                              .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                                .fromSerializer(new GenericJackson2JsonRedisSerializer()));
        
        return RedisCacheManager.builder(redisConnectionFactory)
            .cacheDefaults(config)
            .build();
    }
}

@Service
public class ProductCategoryService {
    
    @Autowired
    private CategoryRepository categoryRepository;
    
    // 获取分类信息
    @Cacheable(value = "categories", key = "#categoryId")
    public Category getCategory(Long categoryId) {
        // 缓存未命中时自动调用此方法并缓存结果
        return categoryRepository.findById(categoryId)
            .orElseThrow(() -> new CategoryNotFoundException("Category not found: " + categoryId));
    }
    
    // 获取分类下的所有商品
    @Cacheable(value = "category_products", key = "#categoryId")
    public List<Product> getProductsByCategory(Long categoryId) {
        return categoryRepository.findProductsByCategoryId(categoryId);
    }
    
    // 更新分类信息
    @CachePut(value = "categories", key = "#category.id")
    @CacheEvict(value = "category_products", key = "#category.id")
    public Category updateCategory(Category category) {
        // 更新数据库并自动更新缓存
        return categoryRepository.save(category);
    }
    
    // 添加商品到分类
    @CacheEvict(value = "category_products", key = "#categoryId")
    public void addProductToCategory(Long productId, Long categoryId) {
        categoryRepository.addProductToCategory(productId, categoryId);
    }
}
```
#### 详细解释
1. 缓存配置：
- 使用Spring Cache框架配置Redis作为缓存存储
- 设置默认过期时间为24小时
- 配置JSON序列化，使缓存内容可读
2. 读取流程（Read Through）：
- 使用@Cacheable注解标记方法
- Spring自动检查缓存，未命中时执行方法并缓存结果
- 对开发者透明，无需手动管理缓存逻辑
3. 更新流程（Write Through）：
- 使用@CachePut更新分类缓存
- 使用@CacheEvict清除相关的产品列表缓存
- Spring确保数据库和缓存同时更新
4. 为什么选择Read/Write Through：
- 分类数据相对简单且稳定，适合框架管理
- 减少重复的缓存管理代码
- 框架自动处理缓存和数据库的同步
5. 缓存策略细节：
- 分类基本信息使用@CachePut更新缓存
- 分类商品列表使用@CacheEvict使缓存失效（因为列表可能变化较大）


## 综合考量与最佳实践
在实际电商系统中，通常会综合使用多种缓存策略,这里我总结了下面几个部分：
### 数据分级
- 核心交易数据（库存、价格）：使用延迟双删或强一致性策略
- 展示类数据（商品信息、图片）：使用Cache Aside
- 统计类数据（评论数、浏览量）：使用Write Behind
### 缓存过期时间差异化
- 频繁变化的数据设置短过期时间（如库存5分钟）
- 稳定数据设置长过期时间（如商品基本信息1天）
- 关键数据可以不设过期时间，通过显式更新维护一致性
### 监控与预警
- 监控缓存命中率，低于阈值时报警
- 监控数据库和缓存的一致性，发现异常时自动修复
- 监控缓存服务健康状态，及时发现问题
### 降级策略
- 缓存服务不可用时，临时直接读取数据库
- 数据库压力过大时，可以返回稍旧的缓存数据
- 关键业务和非关键业务分离，保证核心功能可用



## 总结
没有完美的缓存策略，关键是根据业务特点和数据特性选择最合适的策略，并通过监控和调整不断优化系统表现




