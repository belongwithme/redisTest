@[toc](应用层)

# HTTP
## HTTP协议的特点是什么？
个人版本回答：
首先，它是无状态的，这意味着服务器不会在多个请求之间保存客户端信息。这种设计使服务器能够高效处理并发请求，但也带来了session管理的挑战。
其次，HTTP是文本协议，使用人类可读的格式进行通信，这使得调试和开发非常方便。但这也导致了协议报文有较大的开销，HTTP/2和HTTP/3通过二进制格式改进了这一点。
HTTP的无连接特性在早期版本中尤为明显，HTTP/1.0每个请求都需要建立新的TCP连接。虽然HTTP/1.1引入了持久连接，但协议本身的设计理念仍是请求-响应模式，不适合推送类应用场景。
HTTP协议可扩展性强，通过首部字段轻松扩展功能，如缓存控制、认证、内容协商等。这种设计使它能够适应互联网发展中的各种需求变化。
最后，HTTP建立在TCP之上，这种选择保证了通信的可靠性，但也继承了TCP的一些问题，比如队头阻塞。
## HTTP 报文格式？怎么分割的？
对于请求报文，核心部分是请求行，它定义了"意图"（HTTP方法）、"资源"（URL）和"规则版本"（HTTP版本）。它告诉服务器"我想对什么资源做什么操作"。
对于响应报文，核心是状态行，它包含了"规则版本"和"结果代码"（状态码及描述），简洁地表达了请求处理的结果。
两种报文都包含头部字段，这是HTTP可扩展性的关键。头部采用键值对设计，允许在不破坏协议结构的情况下添加新功能。从协议设计角度看，这种扩展机制非常优雅。
报文分割采用了明确的分隔符机制：CRLF（\r\n）用于行分隔，空行（两个CRLF）用于区分头部和主体。这种基于文本的分割方式使得报文易于人类阅读，但也增加了解析的复杂性和传输的开销。
HTTP/2和HTTP/3改变了这种文本格式，采用二进制帧结构，但逻辑上仍保持了相同的组织方式，证明了这种格式设计的合理性和可进化性。
## HTTP默认的端口是什么？
HTTP选择80作为默认端口.
## HTTP 有什么方法？
HTTP方法本质上是对资源操作的语义化定义，反映了HTTP协议的设计理念。
从REST架构风格来看，这些方法形成了一套完整的资源操作语义：
- GET方法体现了"读取"语义，设计上不应改变资源状态，符合分布式系统中安全操作的概念
- POST方法表示"创建"或"处理"，它的设计最为灵活，但也容易被滥用
- PUT和DELETE方法分别对应"完全替换"和"删除"操作，使API具有直观的语义
从协议演进角度，早期HTTP主要使用GET和POST，而随着REST架构的流行，PUT、DELETE等方法得到更广泛应用。这反映了Web从"文档传输"向"应用平台"的转变。
从安全角度，不同方法有不同的安全特性:
- HEAD和OPTIONS等方法主要用于元数据操作，提供了在不传输完整资源的情况下进行通信的能力。
- CONNECT方法则专为安全隧道设计，在HTTPS代理中扮演关键角色。
- PATCH方法是后来加入的，它解决了PUT方法的一个局限 - 无法进行部分更新。这展示了HTTP协议如何根据实际需求不断完善其语义体系。
## 分析一下哪些HTTP方法是安全或幂等的？
安全性和幂等性是理解HTTP方法语义的两个核心概念，它们反映了分布式系统设计中的重要原则。
安全性指的是方法不应该有副作用，即不改变服务器资源状态。这一概念源自分布式系统中对只读操作的区分。GET、HEAD、OPTIONS和TRACE方法被设计为安全的，这使得这些操作可以被缓存、预取.
幂等性则是分布式系统处理失败重试的基础 - 当操作可能因网络问题需要重试时，幂等操作可以安全地重复执行而不产生额外影响。PUT和DELETE是典型的幂等方法 - 多次替换同一资源的效果与一次相同，多次删除已删除的资源也不会有额外影响。
## GET 和 POST 请求的区别？追问：GET 请求一定是安全且幂等的吗？
GET和POST的区别反映了HTTP协议设计中对不同操作语义的抽象。
从协议语义角度，GET设计用于获取资源，而POST用于提交数据以触发状态变化。
如果开发者遵循规范去处理请求,那就是安全且幂等的.
但是如何开发者处理get请求的方式是新增数据,这时候GET请求就不是安全且幂等的.
比如我在一个get 方法里插入一个数据库记录,这时候GET请求就不是安全且幂等的.

## HTTP 有什么状态码？
HTTP状态码是协议设计中对请求处理结果的抽象和分类，它们形成了一种简洁有效的通信机制。
从架构角度，状态码的分类反映了Web系统的关注点分离：
1xx：反映了HTTP协议的交互机制，如100 Continue允许客户端分阶段发送请求，这对处理大型上传很有用
2xx：表示正常流程的各种场景，如200 OK表示成功，201 Created表示资源创建，206 Partial Content支持断点续传
3xx：处理资源定位变化，如301永久重定向和302临时重定向，这是Web资源管理的重要机制
4xx：表示客户端错误，如400表示请求格式错误，401需要身份验证，403表示权限不足，404表示资源不存在
5xx：表示服务端错误，如500内部错误，503服务不可用
从系统设计角度，这种分类既是通信协议，也是错误处理机制。客户端可以根据状态码大类判断错误归属并采取相应的恢复策略。例如，面对4xx错误，客户端应修改请求；面对5xx错误，可能需要重试或降级处理。
从开发实践看，状态码使得API设计更加规范化，也便于监控和调试。例如，监控系统可以根据状态码分布判断系统健康状况，日志分析可以根据状态码识别异常模式。
状态码的设计充分体现了HTTP协议"简单但可扩展"的设计理念，在简明扼要地传达信息的同时，也为特定应用场景预留了定制空间。
## 什么情况下会出现502错误码呢？
502 Bad Gateway 错误本质上是一个"中间人"告诉你"我联系后端服务时出了问题"。
在典型的Web架构中，客户端请求首先到达的往往是反向代理层（如Nginx、HAProxy），然后才转发到实际处理业务逻辑的应用服务器。502错误正是这个代理层报告的"我无法正确获取或解析来自后端的响应"。
常见的502场景包括：
- 应用服务宕机：代理尝试连接应用服务器但连接被拒绝
- 通信协议不匹配：例如代理配置为HTTP但应用服务使用了HTTPS
- 响应头格式错误：应用服务器返回了不符合HTTP规范的响应
- 应用服务异常退出：在处理请求过程中崩溃，导致连接突然关闭
## 有个服务出现了504，你觉得这个服务器遇到了什么问题？
从根因分析角度，504通常可以追溯到以下几类问题：
- 处理时间过长：后端服务需要执行耗时操作，如复杂查询、大数据处理或外部API调用。这反映了系统设计中可能存在的计算密集型操作未被适当优化或异步化。
- 资源竞争：后端服务面临资源争用，如数据库连接池耗尽、线程池饱和或内存压力大。这通常是系统在高并发场景下的容量问题。
- 配置不匹配：代理层的超时设置与后端处理时间不匹配。例如，如果Nginx配置了10秒超时，但后端操作需要15秒，就会出现504。
## 重定向是哪一类状态码？临时重定向和永久重定向有什么区别？
重定向状态码（3xx系列）体现了HTTP协议对资源位置变化的处理机制。从Web架构角度，重定向是实现资源定位灵活性的关键机制。
从信息论角度，重定向本质上是一种"间接寻址"：告诉客户端"你要找的东西不在这里，去那里找"。3xx状态码正是这种寻址重定向的语义编码。
永久重定向（301、308）和临时重定向（302、303、307）的核心区别在于资源位置变化的持久性：
永久重定向表示资源已经永久移动到新位置。这种语义有几个重要影响：
- 客户端被鼓励更新书签
- 浏览器会缓存这个重定向结果，后续直接访问新地址
- 搜索引擎会将索引从旧地址迁移到新地址，传递链接权重
临时重定向表示资源只是暂时位于其他位置。其影响是：
- 客户端不应更新书签
- 浏览器每次仍会先访问原地址
- 搜索引擎维持原地址的索引
## HTTP是长连接还是短连接？
最初的HTTP/1.0默认采用短连接模式，这与其设计初衷 - 作为一个简单的文档获取协议 - 是一致的。  
每次请求都建立新连接，处理完立即关闭，简化了服务器实现，但在复杂网页场景下效率低下。
随着Web应用复杂度增加，HTTP/1.1标准化了长连接机制，将其设为默认行为。
这是协议对当时Web现状的适应 - 一个页面需要获取多个资源，复用TCP连接可以显著提高性能。
从底层网络角度看，HTTP连接模式反映了对TCP协议特性的理解和优化。
TCP连接建立需要三次握手，还有慢启动机制。短连接模式下，每个小资源请求都要经历这些开销，而长连接则可以分摊这些成本。

## HTTP长连接和短连接的区别？
从连接生命周期角度，短连接遵循"一次性"原则：请求完成即释放TCP连接，符合HTTP最初的无状态设计理念。长连接则引入了"复用"概念：将连接视为可重复利用的资源，在多个请求间共享。
从性能开销分析，两种模式各有权衡：
短连接在每次请求都会经历TCP的三次握手和慢启动过程，这对小型、不频繁的交互是额外开销
长连接避免了重复的连接建立成本，但维持空闲连接也消耗服务器资源（如文件描述符）
从应用场景角度，短连接更适合小型、不频繁的交互，如API请求；长连接则更适合需要持续数据交换的场景，如流媒体传输。

## HTTP长连接有什么好处？
HTTP长连接的优势体现在多个层面，反映了对TCP/IP协议栈特性的深度优化。
从网络性能角度，长连接消除了TCP连接建立的额外开销，这包括：
- 避免三次握手延迟（在高延迟网络如移动网络中尤其明显）
- 绕过TCP慢启动阶段，使连接维持在较高的拥塞窗口大小
- 如果是HTTPS，还节省了TLS握手的复杂计算和多次往返
从资源利用角度，长连接提供了更高效的系统资源使用：
- 服务器减少了建立和销毁套接字的CPU开销
- 降低了网络接口的SYN包处理压力
从用户体验视角，长连接直接转化为更快的页面加载时间：
- 现代网页通常包含几十甚至上百个资源请求
- 短连接模式下，连接开销可能占总加载时间的10-30%
- 长连接模式下，连接开销可以忽略不计，显著提升页面加载速度
## HTTP/1.0 和 HTTP/1.1 的区别？
HTTP/1.0和HTTP/1.1的区别反映了Web从简单文档共享向复杂应用平台转变的技术演进。
1. 从连接管理角度看，HTTP/1.1引入默认长连接是最显著的变化。
这不仅是单纯的性能优化，而是对Web应用场景根本性变化的适应 — 一个网页不再是单一文档，而是多资源复合体。
这一变化将每次请求的TCP连接开销从O(n)降低到O(1)，对于包含几十个资源的页面，性能提升显著。
2. 从资源处理角度，HTTP/1.1的范围请求（Range）支持解决了大文件传输问题。
在网络不稳定环境下，能够恢复传输而非重新开始，这对媒体流和大文件下载至关重要。
这一功能反映了HTTP从纯文本传输向多媒体平台的演进。
3. 从互联网架构视角，Host头的引入看似简单，却对Web基础设施产生深远影响。
它使得虚拟主机技术成为可能，大幅降低了网站托管成本，促进了早期互联网的快速发展。
这一变化使HTTP真正成为域名系统之上的应用层协议，而非简单的文件传输工具。
4. 从可扩展性考量，HTTP/1.1引入的OPTIONS方法为跨域资源共享(CORS)等后续技术奠定了基础，PUT和DELETE方法的标准化则为REST架构风格提供了协议支持。
这些改进使HTTP从单纯的文档获取协议转变为应用状态传输的通用协议。
## HTTP/1.1 和 HTTP/2.0 的区别？
HTTP/2相对HTTP/1.1的变革体现了对Web应用性能瓶颈的系统性突破.
1. 从传输框架看，HTTP/2抛弃了文本行分隔的传统，转而采用二进制帧结构。
这种二进制编码使得协议解析更为高效，也为后续的多路复用、流量控制等高级特性奠定了基础。
2. 从并发模型角度，HTTP/2的多路复用是对HTTP/1.1最大痛点的直接回应。
HTTP/1.1的串行请求处理（即使使用6个并行连接）导致了严重的"队头阻塞"问题，而HTTP/2通过流的概念在单一连接上并行处理请求。
这不仅提高了带宽利用率，还减少了TCP连接消耗，特别适合复杂的现代Web应用。
3. 从资源优先级角度，HTTP/2引入了请求优先级机制，使浏览器能够表达不同资源的重要性。
这使关键渲染路径上的资源能优先处理，提升用户体验的感知性能。
## HTTP/2.0 和 HTTP/3.0 的区别？
HTTP/3相较于HTTP/2的根本性变革在于抛弃了TCP这一互联网半个世纪以来的基石协议，重构了Web通信的传输基础。
1. 从协议架构角度，HTTP/3基于QUIC（基于UDP的传输协议）而非TCP，这不是简单的替换，而是对传输层和应用层边界的重新定义。
QUIC将传统上由操作系统内核实现的传输协议功能移至用户空间，实现了更灵活的协议进化和部署。
2. 从性能瓶颈看，HTTP/3彻底解决了HTTP/2中仍然存在的TCP队头阻塞问题。
尽管HTTP/2通过多路复用解决了应用层队头阻塞，但在TCP层面，单个数据包的丢失仍会阻塞整个连接的数据传输。
HTTP/3通过QUIC的独立数据流，实现了真正的传输级隔离，使得一个流的丢包不会影响其他流的数据传输，这对不稳定的网络环境（如移动网络）尤为重要。
3. 从连接建立视角，HTTP/3将握手延迟从TCP+TLS的多次往返（2-3 RTT）优化至仅需1个RTT，甚至在再次连接时可以实现0-RTT握手。
这种优化对首次页面加载性能和服务迁移场景具有显著价值。
## HTTP是无状态的吗？
HTTP的无状态设计是其核心架构特性之一.
无状态是HTTP的一个有意识的选择，而非局限。
这种设计使服务器无需在请求间保存客户端信息，每个请求都带有处理它所需的全部上下文。
这种简洁设计带来了几个核心优势：
1. 无状态促进了服务器的可扩展性。由于不需要跟踪会话状态，服务器可以轻松处理大量并发连接，也更容易进行横向扩展。
2. 无状态提高了系统稳定性。服务器重启或崩溃不会丢失会话信息，因为这些信息本来就不存在。请求处理逻辑更为简单，减少了出错可能性。
但随着Web应用从简单的文档传输向复杂的交互式应用演进，纯粹的无状态模型显然不够用。
所有，我们看到了一系列在HTTP无状态基础上构建有状态交互的技术方案:
- Cookie机制在客户端存储状态，每次请求自动带上
- Session在服务端存储状态，通过标识符关联
- Token（如JWT）将状态信息编码并签名，实现可验证的客户端状态存储
这些技术本质上是在维持HTTP协议无状态性的同时，在应用层实现状态管理。它们不是对HTTP无状态的否定，而是在其之上的扩展。
我们可以理解为：HTTP协议本身不关心状态，但它提供了传递和维护状态所需的机制。
## HTTP 用户后续的操作，服务端如何知道属于同一个用户？追问：如果服务端是一个集群机器？
HTTP作为无状态协议，本身并不提供用户标识机制，但Web系统需要识别用户身份以提供个性化服务。这一矛盾推动了多种用户识别技术的发展。
从技术演进角度，识别同一用户主要经历了几个阶段：
1. 早期Web采用Cookie机制，通过在客户端存储服务器发送的小数据片段，并在后续请求中自动附加。Cookie作为客户端状态载体，解决了最基本的用户识别需求，但安全性和容量有限。
2. 随后发展出Session机制，将核心状态数据存储在服务端，仅通过Cookie传递会话标识符。这种方式提高了安全性和存储容量，但引入了服务端状态管理的复杂性。
3. 现代Web应用则越来越多采用Token认证（如JWT），实现了自包含的认证信息，使服务端无需存储会话状态

当服务端是集群架构时，用户识别面临更大挑战。从架构演进看，解决方案经历了几个代际：
1. 第一代解决方案是粘性会话（Session Sticky）。负载均衡器确保同一用户的请求总是路由到同一服务器。这种方案实现简单，但降低了系统弹性，节点故障会导致用户会话丢失。
2. 第二代方案是会话共享或分布式缓存。将会话数据存储在Redis等共享存储中，所有节点访问同一数据源。这解决了节点故障问题，但引入了额外的网络开销和复杂性。
3. 第三代方案是无状态架构，主要通过JWT等自包含令牌实现。令牌中包含足够的用户信息和签名，任何服务节点都能独立验证而无需查询中央存储。这种方案扩展性最佳，但令牌管理（如过期、撤销）变得复杂。

## 如果禁用 Cookie，怎么实现 Session？
禁用Cookie场景下的Session实现，本质上是解决"如何在无状态HTTP请求间传递状态标识"的问题。
从技术角度，这涉及寻找Cookie之外的客户端状态传递通道。
需要一个稳定的机制在请求间传递会话标识符(SessionID)。主要可选方案有：
1. URL参数传递是最直接的替代方案。通过在每个URL末尾附加?sessionid=xyz123形式的查询参数，确保后续导航携带会话标识。
这种方法的核心挑战在于：服务器需要重写响应中的所有URL（包括链接、表单action、重定向URL等），确保会话标识一直存在。
从实现角度，这需要强大的HTML解析和重写机制，增加了服务器处理负担。
2. 路径参数将会话标识作为URL路径的一部分，如/session/xyz123/resource。
3. 隐藏表单字段适用于表单提交场景。
4. 前端存储+JavaScript是现代Web应用常用方案。
利用localStorage/sessionStorage存储会话标识，通过JavaScript拦截请求（如AJAX）并添加标识。
这种方法实现灵活，但完全依赖JavaScript，且需要在首次访问时通过其他手段建立会话。

## cookie 和 session 的区别？
Cookie和Session代表了Web状态管理的两种不同方案：客户端状态与服务端状态。
从存储原理看，Cookie是将数据存储在用户浏览器中的小型文本文件，而Session则是在服务器上创建的临时数据结构。这一根本区别导致了一系列衍生差异。
从安全模型角度，Cookie实现了"信任客户端"的状态管理 - 服务器将状态委托给客户端保管。这种模式简化了服务器实现，但面临客户端数据被篡改的风险。
本质上是一种"弱信任"架构。
相比之下，Session代表"服务器权威"模型 - 服务器保留完全控制权，客户端仅持有引用(SessionID)。这种架构下数据操作更安全可控，但增加了服务器存储负担和集群一致性复杂度。

从性能权衡角度，Cookie与Session各有利弊：
- Cookie随每个请求自动发送，当Cookie数量增长时会增加网络开销
- Session仅传递标识符，减轻了网络负担，但可能增加服务器内存压力和I/O开销（取决于存储方式）
从架构扩展性看，Session在分布式系统中面临更大挑战。
服务器横向扩展时，Session数据必须通过共享存储、会话复制或粘性会话等机制确保一致性，增加了系统复杂度。
而Cookie作为客户端存储，天然支持分布式架构。
从生命周期管理角度，Cookie支持精确的过期控制，包括持久Cookie和会话Cookie，甚至可以设定未来特定时间点失效。
Session的生命周期则主要由服务器控制，通常基于非活动时间自动过期。
从现代Web开发实践看，Cookie和Session往往协同工作：
Cookie用于存储SessionID，而非直接存储敏感数据。
同时，随着无状态REST API和前后端分离架构流行，基于Token的认证（特别是JWT）逐渐成为Session的替代方案，实现了无状态但安全的身份验证。
## Cookie、Session 和 Token 有什么区别？
从架构模式角度,体现状态管理的不同范式：
- Cookie采用"客户端状态"模式，状态直接存储在用户设备上
- Session采用"服务端状态"模式，服务器存储状态，客户端仅持有引用
- Token（特别是JWT）采用"自包含证明"模式，状态编码在令牌中，通过密码学验证确保其可信度
从技术演进视角，它们反映了不同时代的Web架构需求：
- Cookie起源于早期Web，解决了基本的状态识别问题
- Session应对了安全性挑战，将敏感数据移至服务端
- Token则回应了分布式系统和前后端分离架构的崛起，重新拥抱无状态设计
者处理状态信息的方式不同：
- Cookie直接在客户端存储明文或简单加密的数据
- Session在服务端以任意格式存储数据，仅向客户端暴露引用
- Token（尤其是JWT）以结构化方式编码信息，并附加签名或加密保护，形成自验证的信息包
从安全模型看，三者各有优劣：
- Cookie面临XSS、CSRF等攻击风险，现代浏览器通过SameSite、HttpOnly等属性提供部分防护
- Session集中管理提高了安全控制力，但面临会话固定等风险
- Token通过签名防篡改，但一旦泄露，在到期前难以撤销（除非实现黑名单，但这又回到了有状态设计）
## 简述 JWT 的原理和校验机制
WT(JSON Web Token)是一种开放标准(RFC 7519)，用于在网络应用间传递声明的紧凑且独立的方式。
JWT的基本结构由三部分组成，用点(.)分隔：
1. 头部(Header)：指定签名算法和令牌类型，通常使用Base64Url编码
2. 载荷(Payload)：包含声明信息，如用户ID、权限、过期时间等，同样使用Base64Url编码
3. 签名(Signature)：使用header中指定的算法，结合密钥对前两部分进行签名
JWT校验机制流程：
1. 客户端登录成功后，服务器生成JWT并返回
2. 客户端存储JWT，后续请求时在Authorization头部带上
3. 服务器接收请求后，提取JWT并执行验证：
- 验证签名是否有效（使用密钥和指定算法重新计算签名并比对）
- 检查令牌是否过期（验证exp声明）
- 验证发行者和接收者（验证iss和aud声明）
- 根据需要验证其他声明（如nbf-生效时间等）
验证通过后，服务器可信任JWT中的信息，根据其中的用户ID等识别用户
由于JWT的签名机制，客户端无法伪造或修改令牌内容，服务器可以安全地信任令牌中的信息。
## JWT 令牌为什么能够实集群共享？
JWT实现集群共享的核心在于它实现了"计算取代存储"的身份验证范式转变，从根本上解决了分布式系统中的会话同步问题。
1. 从分布式架构角度，传统会话认证面临的最大挑战是状态共享 - 如何确保用户在不同节点间无缝切换。这通常需要复杂的会话复制或集中式存储机制，增加了系统复杂度和单点故障风险。JWT通过将所有必要信息（身份、权限、元数据）编码在令牌本身，彻底消除了这一共享需求。
2. 从信息理论视角，JWT代表一种"自证明信息"设计模式。令牌本身携带了验证自身所需的全部上下文（除了密钥），使得验证过程可以完全本地化。这一特性使得任何系统节点都能独立完成认证决策，无需外部依赖。
从密钥管理角度，JWT极大简化了集群共享需求：
使用对称算法（如HMAC）时，只需在集群中共享相同的密钥
使用非对称算法（如RSA）时，验证节点只需持有公钥，签发节点保留私钥
相比共享整个会话数据库，仅共享密钥大大降低了同步复杂度和安全风险。
3. 从性能角度分析，JWT在集群环境中表现优异：
验证过程是纯计算操作，无I/O等待
避免了跨节点会话查询的网络延迟
减少了中央会话存储的压力和瓶颈
## JWT 有什么缺点？
JWT作为一种认证方案，其缺点本质上是"无状态设计"的两面性 - 解决了分布式扩展问题，但也带来了一系列新的挑战。
从安全管理角度，JWT最显著的问题是"难以撤销"。由于验证不依赖中央存储，一旦签发的令牌在有效期内始终有效，无法像传统会话一样直接从服务器删除。这导致几个实际问题：
- 用户修改权限后，旧令牌仍然有效
- 账户密码被盗后，攻击者获得的令牌无法立即失效
- 安全事件响应变得复杂，无法一键下线所有用户
解决这一问题通常需要引入黑名单机制，但这又部分违背了JWT无状态的设计初衷。
从信息设计角度，JWT的"自包含性"导致了令牌体积问题。一个包含完整用户信息的JWT可能比简单的会话ID大10-100倍，在高频API调用场景下，这会显著增加网络传输开销。
从性能考量看，JWT的签名验证过程尤其是使用非对称算法时，计算开销明显高于简单的会话ID查询。在高并发API场景下，这可能成为性能瓶颈。
总结而言，JWT的缺点主要源于其"无状态"和"自包含"这两个核心特性。这不意味着JWT是一个糟糕的解决方案，而是说它有特定的适用场景。理想情况下，JWT最适合短生命周期、安全要求中等、分布式架构的应用场景，而非所有认证需求的通用解决方案。
## 什么是跨域？什么情况下会发生跨域请求？
跨域本质上是浏览器的安全策略与现代Web应用架构需求之间的一种冲突。
它反映了Web早期的信任边界设计 - 同源策略（Same-Origin Policy）。
同源策略是Web安全的基石之一，诞生于浏览器需要防止恶意网站窃取用户在其他网站的数据或执行操作。
它定义了一个简单而有效的隔离机制：源（协议+域名+端口的组合）作为信任的基本单位，不同源之间的资源交互受到严格限制。
从技术定义上，跨域请求发生在以下任一条件不同时：
- 协议不同：HTTP与HTTPS之间的请求
- 域名不同：example.com与api.example.com之间的请求
- 端口不同：example.com:3000与example.com:8080之间的请求
从架构演进角度，现代Web应用已从单体走向分布式，前后端分离和微服务架构使得跨域请求成为常态而非例外：
- 前端应用通常部署在CDN或专用服务器上
- API服务可能分布在不同的子域或完全不同的域名下
- 第三方服务集成（如支付、地图、社交媒体API）必然涉及跨域请求

## RestFul 是什么？RestFul 请求的 URL 有什么特点？
RESTful架构风格代表了一种对Web本质的深刻理解，它不仅是API设计方法，更是对HTTP协议语义的回归与强化.
REST的核心是将应用看作资源的集合，通过统一接口（HTTP方法）操作这些资源，并通过资源的表述（通常是JSON或XML）在客户端和服务器之间传递状态。
RESTful接口具有几个关键特征：
以资源为中心是最基本原则，URL应当标识资源而非行为。例如，/users表示用户资源集合，/users/42表示特定用户资源。
HTTP方法语义化是REST区别于RPC风格API的关键。REST严格遵循HTTP方法的语义：
- GET用于检索资源，是安全且幂等的
- POST用于创建资源，非幂等
- PUT用于完全替换资源，是幂等的
- PATCH用于部分更新资源
- DELETE用于删除资源，是幂等的

请求URL的特点有:
1. 从资源层级角度，RESTful URL通过路径结构反映资源间的从属关系，如/departments/5/employees表示5号部门的所有员工。
2. 从状态管理视角，RESTful设计强调无状态通信 - 每个请求包含处理该请求所需的全部信息，服务器不依赖客户端的上下文。
3. 从版本控制方面，RESTful API通常以明确的方式包含版本信息，如/v1/users，确保API演进不破坏现有客户端。
# HTTPS（重要）
## HTTP 和 HTTPS 有什么区别？
HTTP与HTTPS的区别本质上是"明文通信"与"加密通信"的对比.
1. 安全性：
- HTTP是明文传输，数据不加密，容易被截获和篡改
- HTTPS通过SSL/TLS协议对数据进行加密，保证传输安全
2. 端口：
- HTTP默认使用80端口
- HTTPS默认使用443端口
3. 证书：
- HTTP不需要证书
- HTTPS需要CA颁发的SSL证书来验证服务器身份
4. 连接过程：
- HTTP直接TCP三次握手
- HTTPS在TCP连接基础上，还需要进行SSL/TLS握手
5. 性能：
- HTTP连接简单，消耗资源少
- HTTPS需要加密解密，消耗更多CPU和内存资源
## 了解过哪些加密算法？
主要了解对称算法,非对称算法和哈希算法这三种
对称加密算法以相同密钥进行加解密，速度快、效率高，是数据加密的主力
非对称加密算法使用公私钥对解决了密钥分发问题，是现代安全通信的基础
哈希算法虽不直接加密数据，但在安全架构中扮演核心角色
## 对称加密和非对称加密是什么？各自有哪些算法？
对称加密遵循"共享秘密"的原则，使用同一密钥进行加密和解密。
它建立在信息混淆和扩散的基础上，通过多轮变换使密文与明文的关系变得难以分析。对称加密的核心优势是效率 - 通常比非对称加密快1000-10000倍，这使其成为批量数据加密的首选。
主要对称加密算法及其特性：
- AES（Advanced Encryption Standard）作为当前标准，提供了三种密钥长度（128/192/256位）.
- DES/3DES的历史演变展示了算法安全性如何随计算能力提升而被重新评估,DES的56位密钥空间在1998年被证明可被暴力破解，而3DES通过多次应用DES延长了算法寿命，但以性能为代价。
对称加密的核心局限是密钥分发问题 - 通信双方需要安全地共享密钥，这在开放网络中是个挑战。
非对称加密基于数学难题的不对称性，使用密钥对（公钥和私钥）。
它们的安全性建立在单向函数的概念上 - 正向计算容易，逆向计算在不知道陷门信息（私钥）的情况下计算上不可行。
## 对称和非对称加密算法的区别？
1. 密钥使用：
- 对称加密：使用相同的密钥进行加密和解密
- 非对称加密：使用一对密钥（公钥加密，私钥解密；或私钥签名，公钥验证）
2. 密钥分发：
- 对称加密：需要通过安全信道分发密钥，这是其主要挑战
- 非对称加密：公钥可以公开分发，解决了密钥分发问题
3. 密钥长度：
- 对称加密：通常使用128-256位密钥
- 非对称加密：通常需要更长密钥（RSA通常1024-4096位）
4. 速度与效率：
- 对称加密：计算速度快，适合大量数据加密
- 非对称加密：计算开销大，速度慢，通常比对称加密慢100-1000倍
5. 应用场景：
- 对称加密：适用于加密大量数据，如文件加密、数据传输
- 非对称加密：适用于身份验证、数字签名和密钥交换

## 假设有一个大文件，大小未知，现在要把它上传到云端，该使用对称加密还是非对称加密方法？
对于加密大型文件上传到云端的场景，应该使用对称加密算法，主要原因是在
1. 性能考量：
- 对称加密算法（如AES）处理速度比非对称加密（如RSA）快100-1000倍
- 大文件加密需要高吞吐量，对称加密更为适合
2. 资源使用：
- 对称加密内存占用较低，适合处理大型文件
- 非对称加密处理大文件会消耗过多计算资源，甚至不可行
不过，完整的解决方案通常结合两种加密方式：
1. 使用对称加密算法（如AES-256）加密实际文件
2. 随机生成对称加密的密钥
3. 使用非对称加密（如RSA）加密这个对称密钥
4. 将加密后的文件和加密后的对称密钥一起上传至云端
这种混合加密方案既保证了性能，也解决了密钥分发问题：
- 文件通过高效的对称加密保护
- 密钥通过安全的非对称加密保护
- 接收方使用私钥解密对称密钥，再用对称密钥解密文件
## HTTPS 建立过程是怎样的？
首先客户端要和服务端先进行 TCP 三次握手建立 TCP 连接，接下来，会进行 TLS 四次握手：
第一次 TLS 握手：客户端首先会发一个 Client Hello 消息，消息里面会告诉服务端，客户端支持的密码套件列表，客户端生成的随机数，这个随机数是用来后面生成对称密钥元素之一。
• 第二次 TLS 握手：当服务端收到客户端的消息后，会返回 Server Hello 消息给客户端，消息里面包含了服务端选择的 TLS 版本号，密码套件，服务端生成的随机数，接着服务端为了证明自己的身份，会发送 Server Certificate 给客户端，这个消息里含有数字证书，随后，服务端发了 Server Hello Done 消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次握手完毕。
• 校验证书：客户端收到服务端的数字证书的时候，会对检验服务端的证书，如果证书是合法的，客户端会用 CA 机构的公钥解密数字证书拿到服务端的公钥。
• 第三次 TLS 握手：客户端再次生成一个随机数，用服务端的公钥加密后，通过 Client Key Exchange 消息传给服务端，服务端收到后，用服务端的私钥解密得到客户端的第三个随机数。到这里，服务端和客户端双方都有 3 个随机数，双方根据已经得到的三个随机数，会根据算法生成对称密钥。生成完对称密钥后，客户端会发一个消息告诉服务端开始使用对称加密方式发送消息，并且还会对之前所有发送的数据做个摘要，再用对称加密加密一下，让服务器做个校验，验证对称密钥是否可用，以及之前握手消息是否有被中途篡改。
• 第四次 TLS 握手：服务端也是同样的操作，发送消息告诉客户端开始用对称加密方式发送消息，并且也会对数据做个摘要，并用对称密钥加密一下，让客户端做个校验，如果双方都验证加密和解密没问题，那么 TLS 四次握手正式完成了。
最后，就用对称密钥加解密 HTTP 请求和响应了。
## 为什么需要三个随机数？
这个生成的随机数其实是一个伪随机,只用一个随机数来生成对称密钥安全性不高，容易被破解，使用三个随机数的话十分接近随机了
这样对称密钥破解难度变高了。
## 一次HTTPS需要几次RTT（就是几个来回）？
RTT是往返延时,HTTPS是四次握手,也就是代表2次往返,那么就是2次RTT.
## 你了解业界现在有一个RTT建立HTTPS连接的方法吗？
基于ECDHE密钥交换的HTTPS连接方案,可以实现1个RTT建立HTTPS连接.
## HTTPS 过程进行了多少次非对称加密？多少次对称加密？
在HTTPS连接过程中：
非对称加密次数：
1. 1次加密：客户端使用服务器公钥加密预主密钥（Pre-master Secret）
2. 1次解密：服务器使用私钥解密获取预主密钥
如果使用RSA密钥交换算法，总共有1次加密和1次解密，即2次非对称加密操作。
如果使用DH/ECDHE密钥交换算法，则没有直接使用RSA加密/解密操作，而是使用非对称算法生成共享密钥，这仍涉及非对称密码学，但不是直接的加密/解密。
对称加密次数：
1. 建立TLS连接后的所有HTTP数据传输都使用对称加密
2. TLS握手过程中的Finished消息也使用对称加密（各一次）
综上：
1. 非对称加密：在RSA密钥交换中，总共2次（1次加密，1次解密）
2. 对称加密：至少2次（客户端和服务端的Finished消息），之后的所有HTTP通信都使用对称加密，次数取决于通信量
个人版本回答:
HTTPS过程中的加密操作数量反映了其安全体系的设计思想 - 利用非对称加密解决密钥分发问题，再使用高效的对称加密保护实际数据传输。
从非对称加密角度看，具体操作次数取决于使用的密钥交换算法：
在传统的RSA密钥交换方式中，非对称加密发生在以下关键点：
- 客户端使用服务器公钥加密预主密钥（1次加密操作）
- 服务器使用私钥解密获取预主密钥（1次解密操作）
这两次操作是整个安全通道建立的核心，它们解决了如何在不安全信道上安全传递密钥材料的根本问题。
然而，在现代TLS部署中，ECDHE等密钥交换算法更为常见。这种情况下：
- 不再直接使用RSA进行加密/解密操作
- 而是服务器和客户端各自生成临时密钥对，通过Diffie-Hellman算法派生共享密钥
此过程涉及非对称密码学计算，但严格来说不是"加密/解密"操作
从对称加密角度，TLS握手过程中就开始使用对称加密，具体发生在：
- 客户端发送的Finished消息（1次加密，服务端解密）
- 服务端发送的Finished消息（1次加密，客户端解密）
这两次对称加密操作验证了密钥导出成功，并确认握手消息未被篡改。
握手完成后，所有后续HTTP通信都使用协商好的对称密钥加密，包括：
- 所有请求报文（HTTP headers和body）
- 所有响应报文（HTTP headers和body）
这部分对称加密操作次数取决于通信量 - 每个HTTP请求/响应都需要加密和解密，对于复杂网页可能涉及数十甚至数百次加密操作。
从性能角度看，这种"少量非对称加密+大量对称加密"的组合设计是一种权衡 - 利用非对称密码学的安全优势建立初始信任，再利用对称加密的高效特性保护大量数据传输。
## SSL握手流程为什么要使用非对称加密？
感觉主要是为了解决安全通信建立过程中的"先有鸡还是先有蛋"的问题 - 如何在不安全的信道上安全地建立共享密钥。
非对称加密解决了互联网环境下的"陌生人通信"挑战。
非对称加密与数字证书结合，提供了强大的身份验证机制。服务器证书中的公钥经CA签名，客户端通过验证签名确认公钥确实属于目标服务器。
在后续密钥交换中，只有持有对应私钥的真实服务器才能正确解密或响应，从而防止中间人攻击。
## 为什么HTTPS不用非对称加密算法加密HTTP报文？
非对称加密与对称加密之间存在巨大性能差距,非对称加密通常比对称加密慢2-3个数量级.
对于包含大量数据传输的HTTP通信，这种性能差距会导致严重的吞吐量下降和延迟增加。
## HTTPS 会对URL加密吗？
URL是属于HTTP报文头部的信息,HTTPS会对整个HTTP报文都会加密,所以HTTPS是会对URL加密的
## CA 机构如何验证Server身份？
服务端在向CA机构申请证书的时候,CA机构会通过自己的私钥对服务器的一些信息进行数字签名,
然后在HTTPS握手阶段的时候,服务端会发送证书给客户端来验证,客户端实际上已经内置了CA机构的公钥.
所以可以用这个公钥来验证服务器的数字证书是否是可信的.


## 证书是绑定的是什么意思？
代表网站是可信的,浏览器在HTTPS握手阶段会对网站服务器下发的证书进行校验.
如果校验成功,代表网站的身份是可信的,是被CA机构认证过的.
## 自己随便编一个证书可以吗？需要采取什么方法注册？
不可以的.
浏览器在校验这个证书的时候,会认为是非法的证书,这时候浏览器会显示访问的网站是不可信的.
得去CA机构申请证书,浏览器才会认为算是合法的证书,这样才可以正常的访问网站的内容.

# RPC
## RPC的作用是什么？
PRC是远程过程调用,主要运用于微服务之间的通信,它的作用是帮助我们屏蔽网络编程细节,
实现调用远程方法就像调用本地(同一项目中的方法)一样的体验,让我们更专注于业务逻辑,而无需关注底层网络通信的细节.

## 为什么有HTTP协议了？还要用RPC？
HTTP协议是应用层协议,主要用于浏览器与服务器之间的通信,而RPC是远程调用,对应的是本地调用.
RPC的通信可以用HTTP协议,也可以用自定义协议,是不做约束的.
用HTTP传输数据会有比较多的信息,比如头部有各种字段信息,数据载体则一般用json格式,
而RPC因为它定制化更高,可以采用体积更小的protobuf或其他序列化协议去保存结构体数据,同时也不需要像HTTP那样考虑各种浏览器行为.
比如302重定向跳转啥的,因此性能也会更好一些,这也是在公司内部微服务中抛弃HTTP,选择适用RPC最主要的原因.


# Nginx
## Nginx位于七层网络结构中的哪一层？
Nginx位于七层网络结构中的应用层,是应用层的代理服务器.
## Nginx有哪些常见的负载均衡方法？
我了解到的主要有普通轮询、加权轮询、IP哈希、URL哈希、最短响应时间、最短连接这些负载均衡算法。
大体上可以分为下面几类：
• 任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的"平均"可以是绝对数量的平均，也可以是比例或者权重上的平均，比如轮询和加权轮询算法。
• 负载均衡类：负载均衡系统根据服务器的负载来进行分配，可以用CPU负载来衡量，也可以用连接数、I/O使用率、网卡吞吐量等来衡量系统的压力，比如最短连接数算法。
• 性能最优类：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器，比如最短响应时间算法
• Hash类：负载均衡系统根据请求中的某些关键信息进行Hash运算，将相同Hash值的请求分配到同一台服务器上，比如IP哈希和URL算法
## 什么是反向代理？什么是正向代理？
正向代理是代理的客户端这一方,而反向代理是代理服务器这一方,可以通过负载均衡策略,将请求分发到不同的服务器上.
